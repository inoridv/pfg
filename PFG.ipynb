{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7240368",
   "metadata": {},
   "source": [
    "## Exemplo de obtenção de informação dos repositórios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb2b8c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# URLs com filtro para busca no github\n",
    "search_links = [\n",
    "    \"https://api.github.com/search/repositories?q=serverless+language:python&sort=stars&order=desc&page={}\",\n",
    "    \"https://api.github.com/search/repositories?q=serverless+language:javascript&sort=stars&order=desc&page={}\",\n",
    "    \"https://api.github.com/search/repositories?q=function+as+a+service+language:python&sort=stars&order=desc&page={}\",\n",
    "    \"https://api.github.com/search/repositories?q=function+as+a+service+language:javascript&sort=stars&order=desc&page={}\",\n",
    "    \"https://api.github.com/search/repositories?q=faas+language:python&sort=stars&order=desc&page={}\",\n",
    "    \"https://api.github.com/search/repositories?q=faas+language:javascript&sort=stars&order=desc&page={}\"\n",
    "]\n",
    "\n",
    "repos_info = []\n",
    "\n",
    "for search in search_links:\n",
    "    \n",
    "    print(f\"Requesting url {search}\")\n",
    "    \n",
    "    page = 0\n",
    "    \n",
    "    while(True):\n",
    "        print(f\"page {page}\")\n",
    "        \n",
    "        api_result = requests.get(search.format(page))\n",
    "        if api_result.status_code != 200:\n",
    "            print(api_result.text)\n",
    "            break\n",
    "\n",
    "        repos = json.loads(api_result.text)\n",
    "        \n",
    "        # Armazena as informacoes relevantes do repositorio em um objeto\n",
    "        for repo in repos[\"items\"]:\n",
    "            relevant_repo_info = {\n",
    "                \"description\": repo[\"description\"],\n",
    "                \"title\": repo[\"full_name\"],\n",
    "                \"url\": repo[\"html_url\"],\n",
    "                \"language\": repo[\"language\"],\n",
    "                \"owner_url\": repo[\"owner\"][\"html_url\"],\n",
    "                \"clone_url\": repo[\"clone_url\"],\n",
    "                \"included\": True\n",
    "            }\n",
    "\n",
    "            # Logica para exclusao de possiveis falsos positivos\n",
    "            readme_content = requests.get(\n",
    "                relevant_repo_info[\"url\"].replace(\n",
    "                    \"https://github.com\", \n",
    "                    \"https://raw.githubusercontent.com\"\n",
    "                ) \n",
    "                + \"/master/README.md\"\n",
    "            ).text\n",
    "\n",
    "            if \"framework\" in readme_content or \"plugin\" in readme_content:\n",
    "                relevant_repo_info[\"included\"] = False\n",
    "\n",
    "            repos_info.append(relevant_repo_info)\n",
    "        page += 1\n",
    "repos_info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58aa5510",
   "metadata": {},
   "source": [
    "## Extração de métricas dos repositórios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5497ce5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import stat\n",
    "import re\n",
    "import shutil\n",
    "from git import Repo\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "\n",
    "def is_config_file(file):\n",
    "    config_file_rules = [\".json\", \"config.\", \".yml\", \".conf\", \".config\", \"settings.\"]\n",
    "    return any(rule in file for rule in config_file_rules)\n",
    "\n",
    "def get_func_names(file, language):\n",
    "    try:\n",
    "        with open(file, encoding=\"utf-8\") as handle:\n",
    "            content = handle.read()\n",
    "    except UnicodeDecodeError as ex:\n",
    "        return []\n",
    "        \n",
    "    if language == \"Python\":\n",
    "        regex = \"def (.*)\\(\"\n",
    "    elif language == \"JavaScript\":\n",
    "        regex = \"exports\\.(.*) = .*\"\n",
    "\n",
    "    matches = re.findall(regex, content)\n",
    "\n",
    "    return matches\n",
    "\n",
    "def get_func_params(file, language):\n",
    "    if language == \"Python\":\n",
    "        regex = \"def .*\\((.*)\\).*:\"\n",
    "    elif language == \"JavaScript\":\n",
    "        regex = \"exports\\..* = .*\\((.*)\\)\"\n",
    "        \n",
    "    try:\n",
    "        with open(file) as handle:\n",
    "            content = handle.read()\n",
    "    except UnicodeDecodeError as ex:\n",
    "        return []\n",
    "        \n",
    "    matches = re.findall(regex, content)\n",
    "    split_matches = [match.split(\",\") for match in matches]\n",
    "    \n",
    "    return split_matches\n",
    "    \n",
    "def get_file_size(file):\n",
    "    try:\n",
    "        with open(file) as f:\n",
    "            lines = sum(1 for line in f)\n",
    "    except UnicodeDecodeError as ex:\n",
    "        return 0\n",
    "    \n",
    "    return lines\n",
    "\n",
    "def get_comment_amount(file, language):\n",
    "    try:\n",
    "        with open(file) as handle:\n",
    "            content = handle.read()\n",
    "    except UnicodeDecodeError as ex:\n",
    "        return 0\n",
    "    \n",
    "    if language == \"Python\":\n",
    "        comments = len(re.findall(\"^#.*$\", content, flags=re.M))\n",
    "    elif language == \"JavaScript\":\n",
    "        comments = len(re.findall(\"^\\/\\*.*$\", content, flags=re.M))\n",
    "        comments += len(re.findall(\"^\\/\\/.*$\", content, flags=re.M))\n",
    "    \n",
    "    return comments\n",
    "\n",
    "def try_detect_provider(file, language):\n",
    "    try:\n",
    "        with open(file) as handle:\n",
    "            content = handle.read()\n",
    "    except UnicodeDecodeError as ex:\n",
    "        return []\n",
    "    \n",
    "    if language == \"Python\":\n",
    "        if \"boto3\" in content:\n",
    "            return \"AWS\"\n",
    "        if \"azure.functions\" in content or \"function.json\" in file:\n",
    "            return \"AZURE\"\n",
    "        if \"google.cloud\" in content:\n",
    "            return \"GCP\"\n",
    "    elif language == \"JavaScript\":\n",
    "        if \"aws-sdk\" in content or \"exports.handler\" in content:\n",
    "            return \"AWS\"\n",
    "        if \"azure/functions\" in content or \"function.json\" in file:\n",
    "            return \"AZURE\"\n",
    "        if \"google-cloud\" in content:\n",
    "            return \"GCP\"       \n",
    "    \n",
    "    return None\n",
    "        \n",
    "\n",
    "def get_metrics(target_repo):\n",
    "    metricas = {}\n",
    "    max_depth = 0\n",
    "    total_folders = 0\n",
    "    total_files = 0\n",
    "    code_files_per_folder = []\n",
    "    name_size_per_func = []\n",
    "    params_per_func = []\n",
    "    total_config_files = 0\n",
    "    amount_external_libs = 0\n",
    "    amount_lines_per_code_file = []\n",
    "    amount_lines_per_config_file = []\n",
    "    amount_funcs_per_file = []\n",
    "    provider = None\n",
    "    amount_comments_per_file = []\n",
    "\n",
    "    for dir_name, subdirs, files in os.walk(\"repo_teste\"):\n",
    "        ## da pra pensar em excluir o readme e gitignore dos arquivos se relevante\n",
    "        if \".git\" in dir_name:\n",
    "            continue\n",
    "\n",
    "        if \"dir_name\" == \"repo_teste\":\n",
    "            metricas[\"root_folder_amount\"] = len(subdirs)\n",
    "            metricas[\"root_file_amount\"] = len(files)\n",
    "\n",
    "        depth = len(dir_name.split(\"/\"))-1\n",
    "        if len(dir_name.split(\"/\"))-1 >= max_depth:\n",
    "            max_depth = depth\n",
    "\n",
    "        total_files += len(files)\n",
    "        total_folders += len(subdirs) if \".git\" not in subdirs else len(subdirs)-1\n",
    "\n",
    "        config_files = [file for file in files if is_config_file(file)]\n",
    "        total_config_files =+ len(config_files)\n",
    "\n",
    "        for config_file in config_files:\n",
    "            amount_lines_per_config_file.append(get_file_size(dir_name + \"/\" +config_file))\n",
    "            if provider == None:\n",
    "                provider = try_detect_provider(dir_name + \"/\" +config_file, target_repo[\"language\"])\n",
    "\n",
    "        if target_repo[\"language\"] == \"Python\":\n",
    "            code_files = [file for file in files if \".py\" in file]\n",
    "\n",
    "            for code_file in code_files:\n",
    "                func_names = get_func_names(dir_name + \"/\" + code_file, \"Python\")\n",
    "                func_params = get_func_params(dir_name + \"/\" + code_file, \"Python\")\n",
    "                name_size_per_func = name_size_per_func + [len(name) for name in func_names]\n",
    "                params_per_func = params_per_func + [len(params) for params in func_params]\n",
    "                amount_funcs_per_file.append(len(func_names))\n",
    "                amount_lines_per_code_file.append(get_file_size(dir_name + \"/\" +code_file))\n",
    "                amount_comments_per_file.append(get_comment_amount(dir_name + \"/\" + code_file, \"Python\"))\n",
    "                \n",
    "                if provider == None:\n",
    "                    provider = try_detect_provider(dir_name + \"/\" + code_file, \"Python\")\n",
    "\n",
    "            amount_code_files = len(code_files)\n",
    "            code_files_per_folder.append(amount_code_files)\n",
    "\n",
    "            if \"requirements.txt\" in files:\n",
    "                amount_external_libs = get_file_size(dir_name + \"/\" + 'requirements.txt')\n",
    "\n",
    "        elif target_repo[\"language\"] == \"JavaScript\":\n",
    "            code_files = [file for file in files if \".js\" in file ]\n",
    "            \n",
    "            for code_file in code_files:\n",
    "                func_names = get_func_names(dir_name + \"/\" + code_file, \"JavaScript\")\n",
    "                func_params = get_func_params(dir_name + \"/\" + code_file, \"JavaScript\")\n",
    "                name_size_per_func = name_size_per_func + [len(name) for name in func_names]\n",
    "                params_per_func = params_per_func + [len(params) for params in func_params]\n",
    "                amount_funcs_per_file.append(len(func_names))\n",
    "                amount_lines_per_code_file.append(get_file_size(dir_name + \"/\" +code_file))\n",
    "                amount_comments_per_file.append(get_comment_amount(dir_name + \"/\" + code_file, \"JavaScript\"))\n",
    "                \n",
    "                if provider == None:\n",
    "                    provider = try_detect_provider(dir_name + \"/\" + code_file, \"Python\")\n",
    "            \n",
    "            amount_code_files = len(code_files)\n",
    "            code_files_per_folder.append(amount_code_files)\n",
    "            \n",
    "            if \"package.json\" in files:\n",
    "                amount_external_libs = get_file_size(dir_name + \"/\" + 'package.json')\n",
    "            \n",
    "    metricas[\"max_depth\"] = max_depth\n",
    "    metricas[\"total_files\"] = total_files\n",
    "    metricas[\"total_folders\"] = total_folders\n",
    "    metricas[\"total_code_files\"] = sum(code_files_per_folder)\n",
    "    metricas[\"avg_code_files_per_folder\"] = metricas[\"total_code_files\"] / metricas[\"total_folders\"]\n",
    "    metricas[\"total_funcs\"] = len(name_size_per_func)\n",
    "    metricas[\"avg_func_name_length\"] = sum(name_size_per_func) / len(name_size_per_func)\n",
    "    metricas[\"avg_func_param_amount\"] = sum(params_per_func) / len(params_per_func)\n",
    "    metricas[\"external_lib_amount\"] = amount_external_libs\n",
    "    metricas[\"avg_lines_code_files\"] = sum(amount_lines_per_code_file) / len(amount_lines_per_code_file)\n",
    "    metricas[\"total_code_lines\"] = sum(amount_lines_per_code_file)\n",
    "    metricas[\"avg_lines_config_files\"] = sum(amount_lines_per_config_file) / len(amount_lines_per_config_file) if len(amount_lines_per_config_file) != 0 else 0\n",
    "    metricas[\"avg_func_name_length\"] = sum(name_size_per_func) / len(name_size_per_func)\n",
    "    metricas[\"max_code_files_per_folder\"] = max(code_files_per_folder)\n",
    "    metricas[\"min_code_files_per_folder\"] = min(code_files_per_folder)\n",
    "    metricas[\"max_func_name_length\"] = max(name_size_per_func)\n",
    "    metricas[\"min_func_name_length\"] = min(name_size_per_func)\n",
    "    metricas[\"max_lines_code_files\"] = max(amount_lines_per_code_file)\n",
    "    metricas[\"min_lines_code_files\"] = min(amount_lines_per_code_file)\n",
    "    metricas[\"max_func_param_amount\"] = max(params_per_func)\n",
    "    metricas[\"min_func_param_amount\"] = min(params_per_func)\n",
    "    metricas[\"max_lines_config_files\"] = max(amount_lines_per_config_file) if len(amount_lines_per_config_file) != 0 else 0\n",
    "    metricas[\"min_lines_config_files\"] = min(amount_lines_per_config_file) if len(amount_lines_per_config_file) != 0 else 0\n",
    "    metricas[\"avg_funcs_per_code_file\"] = metricas[\"total_funcs\"] / metricas[\"total_code_files\"]\n",
    "    metricas[\"max_funcs_per_code_file\"] = max(amount_funcs_per_file)\n",
    "    metricas[\"min_funcs_per_code_file\"] = min(amount_funcs_per_file)\n",
    "    metricas[\"avg_comments_per_file\"] = sum(amount_comments_per_file) / len(amount_comments_per_file)\n",
    "    metricas[\"max_comments_per_file\"] = max(amount_comments_per_file)\n",
    "    metricas[\"min_comments_per_file\"] = min(amount_comments_per_file)\n",
    "    metricas[\"total_comments\"] = sum(amount_comments_per_file)\n",
    "    metricas[\"total_config_files\"] = len(amount_lines_per_config_file)\n",
    "    metricas[\"provider\"] = provider\n",
    "    metricas[\"language\"] = target_repo[\"language\"]\n",
    "    return metricas\n",
    "        \n",
    "def clone_repo(repo_url):\n",
    "    repo = Repo.clone_from(target_repo[\"clone_url\"], \"./repo_teste\")\n",
    "    repo\n",
    "    \n",
    "def onerror(func, path, exc_info):\n",
    "    \"\"\"\n",
    "    Error handler for ``shutil.rmtree``.\n",
    "\n",
    "    If the error is due to an access error (read only file)\n",
    "    it attempts to add write permission and then retries.\n",
    "\n",
    "    If the error is for another reason it re-raises the error.\n",
    "    \n",
    "    Usage : ``shutil.rmtree(path, onerror=onerror)``\n",
    "    \"\"\"\n",
    "    import stat\n",
    "    # Is the error an access error?\n",
    "    if not os.access(path, os.W_OK):\n",
    "        os.chmod(path, stat.S_IWUSR)\n",
    "        func(path)\n",
    "    else:\n",
    "        raise\n",
    "    \n",
    "def clear_repo():\n",
    "    shutil.rmtree(\"./repo_teste\", onerror=onerror)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec8d86e",
   "metadata": {},
   "source": [
    "## Execução de extração para repositórios selecionados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52cc12a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_metricas = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ecb9e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definicao dos repositorios selecionados para estudo, no mesmo formato\n",
    "# de dados obtidos pela proposta de codigo de extracao de informacao\n",
    "# de repositorios do github\n",
    "target_repos = [\n",
    "    {\n",
    "        'description': 'honeyλ - a simple, serverless application designed to create and monitor fake HTTP endpoints (i.e. URL honeytokens) automatically, on top of AWS Lambda and Amazon API Gateway',\n",
    "         'title': '0x4D31/honeyLambda',\n",
    "         'url': 'https://github.com/0x4D31/honeyLambda',\n",
    "         'language': 'Python',\n",
    "         'owner_url': 'https://github.com/0x4D31',\n",
    "         'clone_url': 'https://github.com/0x4D31/honeyLambda.git',\n",
    "         'included': True\n",
    "    },\n",
    "    {\n",
    "        'description': 'Serverless email forwarding using AWS Lambda and SES',\n",
    "        'title': 'arithmetric/aws-lambda-ses-forwarder',\n",
    "        'url': 'https://github.com/arithmetric/aws-lambda-ses-forwarder',\n",
    "        'language': 'JavaScript',\n",
    "        'owner_url': 'https://github.com/arithmetric',\n",
    "        'clone_url': 'https://github.com/arithmetric/aws-lambda-ses-forwarder.git',\n",
    "        'included': True\n",
    "    },\n",
    "    {\n",
    "        'description': 'A sample authentication service implemented with a server-less architecture, using AWS Lambda to host and execute the code and Amazon DynamoDB as persistent storage. This provides a cost-efficient solution that is scalable and highly available and can be used with Amazon Cognito for Developer Authenticated Identities.',\n",
    "        'title': 'danilop/LambdAuth',\n",
    "        'url': 'https://github.com/danilop/LambdAuth',\n",
    "        'language': 'JavaScript',\n",
    "        'owner_url': 'https://github.com/danilop',\n",
    "        'clone_url': 'https://github.com/danilop/LambdAuth.git',\n",
    "        'included': True\n",
    "    }, \n",
    "    {\n",
    "        'description': 'The Web Application reference architecture is a general-purpose, event-driven, web application back-end that uses AWS Lambda, Amazon API Gateway for its business logic. It also uses Amazon DynamoDB as its database and Amazon Cognito for user management. All static content is hosted using AWS Amplify Console.',\n",
    "        'title': 'aws-samples/lambda-refarch-webapp',\n",
    "        'url': 'https://github.com/aws-samples/lambda-refarch-webapp',\n",
    "        'language': 'JavaScript',\n",
    "        'owner_url': 'https://github.com/aws-samples',\n",
    "        'clone_url': 'https://github.com/aws-samples/lambda-refarch-webapp.git',\n",
    "        'included': True\n",
    "    },\n",
    "    {\n",
    "        'description': 'A solution to dynamically handle images on the fly, utilizing SharpJS',\n",
    "        'title': 'aws-solutions/serverless-image-handler',\n",
    "        'url': 'https://github.com/aws-solutions/serverless-image-handler',\n",
    "        'language': 'JavaScript',\n",
    "        'owner_url': 'https://github.com/aws-solutions',\n",
    "        'clone_url': 'https://github.com/aws-solutions/serverless-image-handler.git',\n",
    "        'included': True\n",
    "    },\n",
    "    {\n",
    "        'description': 'A Serverless Blog leveraging GraphQL to offer a REST API with only 1 endpoint using Serverless v0.5',\n",
    "        'title': 'serverless/serverless-graphql-blog',\n",
    "        'url': 'https://github.com/serverless/serverless-graphql-blog',\n",
    "        'language': 'JavaScript',\n",
    "        'owner_url': 'https://github.com/serverless',\n",
    "        'clone_url': 'https://github.com/serverless/serverless-graphql-blog.git',\n",
    "        'included': True\n",
    "    },\n",
    "    {\n",
    "        'description': 'Repository for BLESS, an SSH Certificate Authority that runs as a AWS Lambda function',\n",
    "        'title': 'Netflix/bless',\n",
    "        'url': 'https://github.com/Netflix/bless',\n",
    "        'language': 'Python',\n",
    "        'owner_url': 'https://github.com/Netflix',\n",
    "        'clone_url': 'https://github.com/Netflix/bless.git',\n",
    "        'included': True\n",
    "    },\n",
    "    {\n",
    "        'description': 'Repo of AWS Lambda and Azure Functions functions that process streams and send data to Datadog',\n",
    "        'title': 'DataDog/datadog-serverless-functions',\n",
    "        'url': 'https://github.com/DataDog/datadog-serverless-functions',\n",
    "        'language': 'Python',\n",
    "        'owner_url': 'https://github.com/DataDog',\n",
    "        'clone_url': 'https://github.com/DataDog/datadog-serverless-functions.git',\n",
    "        'included': True\n",
    "    },\n",
    "    {\n",
    "        'description': 'Open source application to instantly remediate common security issues through the use of AWS Config',\n",
    "        'title': 'servian/aws-auto-remediate',\n",
    "        'url': 'https://github.com/servian/aws-auto-remediate',\n",
    "        'language': 'Python',\n",
    "        'owner_url': 'https://github.com/servian',\n",
    "        'clone_url': 'https://github.com/servian/aws-auto-remediate.git',\n",
    "        'included': True\n",
    "    },\n",
    "    {\n",
    "        'description': 'Serverless pypi',\n",
    "        'title': 'khornberg/elasticpypi',\n",
    "        'url': 'https://github.com/khornberg/elasticpypi',\n",
    "        'language': 'Python',\n",
    "        'owner_url': 'https://github.com/khornberg',\n",
    "        'clone_url': 'https://github.com/khornberg/elasticpypi.git',\n",
    "        'included': True\n",
    "    },\n",
    "    {\n",
    "        'description': 'Automated serverless logging to S3 via SQS.',\n",
    "        'title': 'ellimilial/sqs-s3-logger',\n",
    "        'url': 'https://github.com/ellimilial/sqs-s3-logger',\n",
    "        'language': 'Python',\n",
    "        'owner_url': 'https://github.com/ellimilial',\n",
    "        'clone_url': 'https://github.com/ellimilial/sqs-s3-logger.git',\n",
    "        'included': True\n",
    "    },\n",
    "    {\n",
    "        'description': 'FastAI PyTorch Serverless API (w/ AWS Lambda)',\n",
    "        'title': 'alecrubin/pytorch-serverless',\n",
    "        'url': 'https://github.com/alecrubin/pytorch-serverless',\n",
    "        'language': 'Python',\n",
    "        'owner_url': 'https://github.com/alecrubin',\n",
    "        'clone_url': 'https://github.com/alecrubin/pytorch-serverless.git',\n",
    "        'included': True\n",
    "    },\n",
    "    {\n",
    "        'description': 'Serverless App that publishes CodeBuild build logs to a publicly accessible location',\n",
    "        'title': 'jlhood/github-codebuild-logs',\n",
    "        'url': 'https://github.com/jlhood/github-codebuild-logs',\n",
    "        'language': 'Python',\n",
    "        'owner_url': 'https://github.com/jlhood',\n",
    "        'clone_url': 'https://github.com/jlhood/github-codebuild-logs.git',\n",
    "        'included': True\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd93f4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for target_repo in target_repos:\n",
    "    clone_repo([target_repo[\"clone_url\"]])\n",
    "    metricas = get_metrics(target_repo)\n",
    "    entrada = {**target_repo, **metricas}\n",
    "    df_metricas = df_metricas.append(entrada, ignore_index=True)\n",
    "    clear_repo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8029af59",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metricas = df_metricas.round(decimals=1)\n",
    "# Exportacao em formato excel caso necessario\n",
    "# df_metricas.to_csv(\"metricas_repos.csv\", sep=\";\", index=False)\n",
    "# print(df_metricas.to_csv(sep=\";\", index=False))\n",
    "df_metricas"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
